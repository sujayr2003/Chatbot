{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalsentence=\"\"\"\n",
    "The MI 80 cm (32 inches) A Series HD Ready Smart Google TV, model L32M8-5AIN, stands out as an excellent choice for those seeking a feature-rich, affordable smart TV. Here’s a detailed look at its performance and features.\n",
    "\n",
    "Display Quality\n",
    "\n",
    "With an HD Ready resolution (1366 x 768 pixels), the 32-inch screen delivers sharp and vibrant visuals. While it doesn’t offer Full HD or 4K, the picture quality is more than adequate for its size, providing clear and bright images. The color reproduction and contrast levels are commendable, ensuring an enjoyable viewing experience for regular TV shows, movies, and casual streaming.\n",
    "\n",
    "Smart Features\n",
    "\n",
    "Running on Google TV, this MI A Series TV brings a wealth of smart features. The interface is user-friendly and integrates seamlessly with Google services. Users have access to a vast library of apps and content from the Google Play Store, including popular streaming services like Netflix, Amazon Prime Video, and YouTube. The inclusion of Google Assistant allows for voice commands, making navigation and content search easy and intuitive.\n",
    "\n",
    "Connectivity\n",
    "\n",
    "This TV comes equipped with multiple connectivity options, including three HDMI ports, two USB ports, and built-in Wi-Fi. These ports ensure that users can easily connect gaming consoles, Blu-ray players, and other devices. The HDMI ARC and CEC support add to the convenience, allowing for simplified control and enhanced audio output.\n",
    "\n",
    "Audio Performance\n",
    "\n",
    "The audio quality on the MI A Series TV is surprisingly robust for its size. It features 20W stereo speakers with DTS-HD support, delivering clear and balanced sound. While it may not replace a dedicated sound system, the built-in speakers are sufficient for most viewing scenarios, providing a decent audio experience.\n",
    "\n",
    "Design and Build\n",
    "\n",
    "The TV sports a sleek and modern design with thin bezels that maximize the viewing area. Its black finish gives it a sophisticated look, easily blending into various home decor styles. The build quality is solid, and it feels durable despite its lightweight nature.\n",
    "\n",
    "Ease of Use\n",
    "\n",
    "Setting up the MI A Series TV is straightforward, thanks to the intuitive Google TV interface and easy-to-follow instructions. The included remote control is ergonomic​\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(originalsentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\System32\\transformers\\src\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\System32\\transformers\\src\\transformers\\generation\\utils.py:1219: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# Initialize the pipeline with the specific model\n",
    "pipe = pipeline(\"text2text-generation\", model=\"mrm8488/t5-base-finetuned-emotion\")\n",
    "sentiment=pipe(originalsentence)\n",
    "print(sentiment[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\System32\\transformers\\src\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'neutral', 'score': 0.888362467288971}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\")\n",
    "sentiment1=classifier(originalsentence)\n",
    "print(sentiment1[0]['label'])   \n",
    "print(sentiment1[0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'neutral', 'score': 0.9648489356040955}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"michellejieli/emotion_text_classifier\")\n",
    "sentiment2=classifier(originalsentence)\n",
    "print(sentiment2[0]['label'])\n",
    "print(sentiment2[0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': '5 stars', 'score': 0.8936719298362732}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"LiYuan/amazon-review-sentiment-analysis\")\n",
    "\n",
    "sentiment3=pipe(originalsentence)\n",
    "print(sentiment3[0]['label'])\n",
    "print(sentiment3[0]['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Windows\\System32\\transformers\\src\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")\n",
    "\n",
    "sentiment4=pipe(originalsentence)\n",
    "print(sentiment4[0]['label'])\n",
    "print(sentiment4[0]['score'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
