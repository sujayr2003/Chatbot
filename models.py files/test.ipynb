{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf=pd.read_csv(r'C:\\Users\\sujay\\Desktop\\Chatbot\\CSVFilesObtainedAfterWebscrapping\\Amazon\\amazon_reviews_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf=newdf.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product_Title</th>\n",
       "      <th>Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Rating_Date</th>\n",
       "      <th>Review_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>redmi note 13 pro (arctic white, 8gb ram, 128g...</td>\n",
       "      <td>my honest reply after using about a month</td>\n",
       "      <td>best allrounder +</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>reviewed in india on 28 april 2024</td>\n",
       "      <td>guys it's actually the best phone after gettin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>redmi note 13 pro (arctic white, 8gb ram, 128g...</td>\n",
       "      <td>my honest reply after using about a month</td>\n",
       "      <td>prashanth</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>reviewed in india on 15 july 2024</td>\n",
       "      <td>battery - even though this phone has decent sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>redmi note 13 pro (arctic white, 8gb ram, 128g...</td>\n",
       "      <td>my honest reply after using about a month</td>\n",
       "      <td>mohammed kasim</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>reviewed in india on 18 august 2024</td>\n",
       "      <td>very good product , battery for active use one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>redmi note 13 pro (arctic white, 8gb ram, 128g...</td>\n",
       "      <td>my honest reply after using about a month</td>\n",
       "      <td>abs</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>reviewed in india on 18 august 2024</td>\n",
       "      <td>its a decent budget phone for everyday usage.h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>redmi note 13 pro (arctic white, 8gb ram, 128g...</td>\n",
       "      <td>my honest reply after using about a month</td>\n",
       "      <td>durairaj p.</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>reviewed in india on 20 june 2024</td>\n",
       "      <td>used for a month and find my genuine review.i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30646</th>\n",
       "      <td>30646</td>\n",
       "      <td>14285</td>\n",
       "      <td>oppo a3x 5g (starry purple, 4gb ram, 64gb stor...</td>\n",
       "      <td>worst camera</td>\n",
       "      <td>camera disappointed me a lot ,worst camera exp...</td>\n",
       "      <td>1.0 out of 5 stars</td>\n",
       "      <td>reviewed in india on 3 august 2024</td>\n",
       "      <td>camera disappointed me a lot  ,worst camera in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30647</th>\n",
       "      <td>30647</td>\n",
       "      <td>14286</td>\n",
       "      <td>oppo a3x 5g (starry purple, 4gb ram, 64gb stor...</td>\n",
       "      <td>worst camera</td>\n",
       "      <td>bishwajit kumar</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>reviewed in india on 12 august 2024</td>\n",
       "      <td>video player is loading.play videoplaymutecurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30648</th>\n",
       "      <td>30648</td>\n",
       "      <td>14287</td>\n",
       "      <td>oppo a3x 5g (starry purple, 4gb ram, 64gb stor...</td>\n",
       "      <td>worst camera</td>\n",
       "      <td>raj</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>reviewed in india on 6 august 2024</td>\n",
       "      <td>it's a good phone in this price range, the bat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30649</th>\n",
       "      <td>30649</td>\n",
       "      <td>14288</td>\n",
       "      <td>oppo a3x 5g (starry purple, 4gb ram, 64gb stor...</td>\n",
       "      <td>worst camera</td>\n",
       "      <td>sandeep</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>reviewed in india on 5 august 2024</td>\n",
       "      <td>this product i purchaed for my wife ....this i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30650</th>\n",
       "      <td>30650</td>\n",
       "      <td>14289</td>\n",
       "      <td>-------</td>\n",
       "      <td>-------</td>\n",
       "      <td>-------</td>\n",
       "      <td>-------</td>\n",
       "      <td>-------</td>\n",
       "      <td>-------</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30651 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1 Unnamed: 0  \\\n",
       "0                0          0   \n",
       "1                1          1   \n",
       "2                2          2   \n",
       "3                3          3   \n",
       "4                4          4   \n",
       "...            ...        ...   \n",
       "30646        30646      14285   \n",
       "30647        30647      14286   \n",
       "30648        30648      14287   \n",
       "30649        30649      14288   \n",
       "30650        30650      14289   \n",
       "\n",
       "                                           Product_Title  \\\n",
       "0      redmi note 13 pro (arctic white, 8gb ram, 128g...   \n",
       "1      redmi note 13 pro (arctic white, 8gb ram, 128g...   \n",
       "2      redmi note 13 pro (arctic white, 8gb ram, 128g...   \n",
       "3      redmi note 13 pro (arctic white, 8gb ram, 128g...   \n",
       "4      redmi note 13 pro (arctic white, 8gb ram, 128g...   \n",
       "...                                                  ...   \n",
       "30646  oppo a3x 5g (starry purple, 4gb ram, 64gb stor...   \n",
       "30647  oppo a3x 5g (starry purple, 4gb ram, 64gb stor...   \n",
       "30648  oppo a3x 5g (starry purple, 4gb ram, 64gb stor...   \n",
       "30649  oppo a3x 5g (starry purple, 4gb ram, 64gb stor...   \n",
       "30650                                            -------   \n",
       "\n",
       "                                           Title  \\\n",
       "0      my honest reply after using about a month   \n",
       "1      my honest reply after using about a month   \n",
       "2      my honest reply after using about a month   \n",
       "3      my honest reply after using about a month   \n",
       "4      my honest reply after using about a month   \n",
       "...                                          ...   \n",
       "30646                               worst camera   \n",
       "30647                               worst camera   \n",
       "30648                               worst camera   \n",
       "30649                               worst camera   \n",
       "30650                                    -------   \n",
       "\n",
       "                                                    Name             Ratings  \\\n",
       "0                                      best allrounder +  5.0 out of 5 stars   \n",
       "1                                              prashanth  4.0 out of 5 stars   \n",
       "2                                         mohammed kasim  5.0 out of 5 stars   \n",
       "3                                                    abs  4.0 out of 5 stars   \n",
       "4                                            durairaj p.  5.0 out of 5 stars   \n",
       "...                                                  ...                 ...   \n",
       "30646  camera disappointed me a lot ,worst camera exp...  1.0 out of 5 stars   \n",
       "30647                                    bishwajit kumar  5.0 out of 5 stars   \n",
       "30648                                                raj  5.0 out of 5 stars   \n",
       "30649                                            sandeep  5.0 out of 5 stars   \n",
       "30650                                            -------             -------   \n",
       "\n",
       "                               Rating_Date  \\\n",
       "0       reviewed in india on 28 april 2024   \n",
       "1        reviewed in india on 15 july 2024   \n",
       "2      reviewed in india on 18 august 2024   \n",
       "3      reviewed in india on 18 august 2024   \n",
       "4        reviewed in india on 20 june 2024   \n",
       "...                                    ...   \n",
       "30646   reviewed in india on 3 august 2024   \n",
       "30647  reviewed in india on 12 august 2024   \n",
       "30648   reviewed in india on 6 august 2024   \n",
       "30649   reviewed in india on 5 august 2024   \n",
       "30650                              -------   \n",
       "\n",
       "                                             Review_Text  \n",
       "0      guys it's actually the best phone after gettin...  \n",
       "1      battery - even though this phone has decent sp...  \n",
       "2      very good product , battery for active use one...  \n",
       "3      its a decent budget phone for everyday usage.h...  \n",
       "4      used for a month and find my genuine review.i ...  \n",
       "...                                                  ...  \n",
       "30646  camera disappointed me a lot  ,worst camera in...  \n",
       "30647  video player is loading.play videoplaymutecurr...  \n",
       "30648  it's a good phone in this price range, the bat...  \n",
       "30649  this product i purchaed for my wife ....this i...  \n",
       "30650                                            -------  \n",
       "\n",
       "[30651 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(r'C:\\Users\\sujay\\Desktop\\Chatbot\\models\\Hinglish_Classification_LSTM_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411,715</span> (5.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,411,715\u001b[0m (5.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,411,713</span> (5.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,411,713\u001b[0m (5.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(review):\n",
    "    prediction = model.predict(review)\n",
    "    sentiment = \"en\" if prediction[0][0] > 0.5 else \"hi\"\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x=bhai (of type <class 'str'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m review\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhai\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mpredict_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreview\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m, in \u001b[0;36mpredict_label\u001b[1;34m(review)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_label\u001b[39m(review):\n\u001b[1;32m----> 2\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreview\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     sentiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiment\n",
      "File \u001b[1;32mc:\\Users\\sujay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\sujay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\__init__.py:120\u001b[0m, in \u001b[0;36mget_data_adapter\u001b[1;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized data type: x=bhai (of type <class 'str'>)"
     ]
    }
   ],
   "source": [
    "review=\"bhai\"\n",
    "predict_label(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "here=\"\"\"\n",
    "    #Training a LSTM model to classify the reviews into English or Hindi based on this dataset\n",
    "    model = load_model(r'C:\\Users\\sujay\\Desktop\\Chatbot\\models\\Hinglish_Classification_LSTM_Model.h5')\n",
    "    with open(r'C:\\Users\\sujay\\Desktop\\Chatbot\\models\\tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "    def predict_label(review):\n",
    "        sequence = tokenizer.texts_to_sequences([review])\n",
    "        padded_sequence = pad_sequences(sequence, maxlen=200)\n",
    "        prediction = model.predict(padded_sequence)\n",
    "        sentiment = \"en\" if prediction[0][0] > 0.5 else \"hi\"\n",
    "        return sentiment\n",
    "\n",
    "    newdf['EnglishorHindi'] = newdf['Review_Text'].apply(predict_label)\n",
    "    print(newdf['EnglishorHindi'].value_counts())\n",
    "    def classify_review_language(text, lang_code):\n",
    "        if lang_code != 'en':  \n",
    "            return 'foreign language'\n",
    "        else:\n",
    "            try:\n",
    "                detected_lang = detect(text)  \n",
    "                if detected_lang == 'en': \n",
    "                   return 'english'\n",
    "                else:\n",
    "                   return 'foreign language'\n",
    "            except:\n",
    "                 return 'unknown'\n",
    "    newdf['Language_Class'] = newdf.apply(lambda row: classify_review_language(row['Review_Text'], row['EnglishorHindi']), axis=1)\n",
    "    st.write(\"After applying the language classification function to the dataset, we get the following results:\")\n",
    "    st.write(newdf)\n",
    "    row_count = newdf.shape[0]\n",
    "    st.write(\"Number of rows:\", row_count)\n",
    "    newdf=newdf[newdf['Language_Class']=='english']\n",
    "    newdf= newdf[['Product_Title', 'Ratings', 'Review_Text']]\n",
    "    st.write(\"After removing any un-necessary columns and the rows from your dataset containing reviews in foreign languages, we get the following dataset:\")\n",
    "    st.write(newdf)\n",
    "    row_count = newdf.shape[0]\n",
    "    st.write(\"Number of rows:\", row_count)\n",
    "    st.write(\"-----------------\")\n",
    "    st.write(\"The frequency distribution of each column in the dataset is:\")\n",
    "    column_names=newdf.columns.tolist()\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for i in column_names:\n",
    "        #st.write(f\"{i}\")\n",
    "        #query = f\"SELECT {i},count(*) FROM newdf group by {i}\"\n",
    "        result = psql.sqldf(query, locals())\n",
    "        st.write(result)\n",
    "        st.write('----------------------')\n",
    "    value_counts = newdf['Ratings'].value_counts()\n",
    "    fig1 = px.bar(value_counts, x=value_counts.index, y=value_counts.values, title=\"Ratings count based on each rating's Frequency\")\n",
    "    st.plotly_chart(fig1)\n",
    "    newdf=newdf.drop_duplicates()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    def remove_stopwords(text):\n",
    "        if isinstance(text, str):\n",
    "            return ' '.join([word for word in word_tokenize(text) if word.lower() not in stop_words])\n",
    "        return text\n",
    "    \"\"\"\n",
    "    #def remove_emojis(text):\n",
    "        #emoji_pattern = re.compile(\"[\"\n",
    "        #u\"\\U0001F600-\\U0001F64F\" u\"\\U0001F300-\\U0001F5FF\"\n",
    "        #u\"\\U0001F680-\\U0001F6FF\" u\"\\U0001F700-\\U0001F77F\"\n",
    "        #u\"\\U0001F780-\\U0001F7FF\" u\"\\U0001F800-\\U0001F8FF\"\n",
    "        #u\"\\U0001F900-\\U0001F9FF\" u\"\\U0001FA00-\\U0001FA6F\"\n",
    "        #u\"\\U0001FA70-\\U0001FAFF\" u\"\\U00002702-\\U000027B0\"\n",
    "        #u\"\\U000024C2-\\U0001F251\" \"]+\", flags=re.UNICODE)\n",
    "        #return emoji_pattern.sub(r'', text)\n",
    "    \"\"\"\n",
    "    def remove_punctuation(text):\n",
    "        return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    pattern = r'\\b(media|video)\\b'\n",
    "    newdf['Review_Text'] = newdf['Review_Text'].apply(lambda x: remove_stopwords(remove_emojis(remove_punctuation(x))))\n",
    "    newdf = newdf[~newdf['Review_Text'].str.contains(pattern, case=False, regex=True)].drop_duplicates()\n",
    "    st.write(\"The dataset after removing stopwords, emojis, punctuation, and rows containing 'media' or 'video':\")\n",
    "    st.write(newdf)\n",
    "    row_count = newdf.shape[0]\n",
    "    st.write(\"Number of rows:\", row_count)\n",
    "    st.title(\"Performing Exploratory Data Analysis on the finally obtaianed preprocessed dataset\")\n",
    "    st.write(\"The statistical inference made about the dataset is as follows:\")\n",
    "    st.write(newdf.describe())\n",
    "    st.write('--------------')\n",
    "    st.write(\"The number of duplicated rows is = \", newdf.duplicated().sum())\n",
    "    st.write('--------------')\n",
    "    st.write(\"The shape of the dataset is as follows:\")\n",
    "    st.write(newdf.shape)\n",
    "    st.write('-------------')\n",
    "    st.write(\"The data types of the dataset are as follows:\")\n",
    "    st.write(newdf.dtypes)\n",
    "    st.write('-------------')\n",
    "    st.write(\"The number of unique values in each column of the dataset are as follows:\")\n",
    "    st.write(newdf.nunique())\n",
    "    st.write('---------------')\n",
    "    st.write(\"The number of missing values in each column of the dataset are as follows:\")\n",
    "    st.write(newdf.isna().sum())\n",
    "    st.write('---------------')\n",
    "    # Save final preprocessed data\n",
    "    st.write(\"Download the final preprocessed data:\")\n",
    "    csv_buffer = io.BytesIO()\n",
    "    newdf.to_csv(csv_buffer, index=False)\n",
    "    csv_buffer.seek(0)  # Go back to the start of the buffer\n",
    "    st.download_button(label=\"Download the final preprocessed CSV File\",data=csv_buffer,file_name=\"preprocessed_data.csv\",mime=\"text/csv\")\n",
    "    \"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
