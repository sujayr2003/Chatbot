{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout,GlobalMaxPooling1D\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score,confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:\\Users\\sujay\\Desktop\\Chatbot\\CSVFiles\\New_Hinglish_Classification_final_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>Word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cricket</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>chal</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>raha</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>hain</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>yaha</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12744</th>\n",
       "      <td>12744</td>\n",
       "      <td>challenge</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12745</th>\n",
       "      <td>12745</td>\n",
       "      <td>winners</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12746</th>\n",
       "      <td>12746</td>\n",
       "      <td>at</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12747</th>\n",
       "      <td>12747</td>\n",
       "      <td>paradise</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12748</th>\n",
       "      <td>12748</td>\n",
       "      <td>photos</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12749 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       english       Word label\n",
       "0            0    cricket    en\n",
       "1            1       chal    hi\n",
       "2            2       raha    hi\n",
       "3            3       hain    hi\n",
       "4            4       yaha    hi\n",
       "...        ...        ...   ...\n",
       "12744    12744  challenge    en\n",
       "12745    12745    winners    en\n",
       "12746    12746         at    en\n",
       "12747    12747   paradise    en\n",
       "12748    12748     photos    en\n",
       "\n",
       "[12749 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['english'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cricket</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chal</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raha</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hain</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yaha</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12744</th>\n",
       "      <td>challenge</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12745</th>\n",
       "      <td>winners</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12746</th>\n",
       "      <td>at</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12747</th>\n",
       "      <td>paradise</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12748</th>\n",
       "      <td>photos</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12749 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word label\n",
       "0        cricket    en\n",
       "1           chal    hi\n",
       "2           raha    hi\n",
       "3           hain    hi\n",
       "4           yaha    hi\n",
       "...          ...   ...\n",
       "12744  challenge    en\n",
       "12745    winners    en\n",
       "12746         at    en\n",
       "12747   paradise    en\n",
       "12748     photos    en\n",
       "\n",
       "[12749 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sujay\\AppData\\Local\\Temp\\ipykernel_11988\\1330269346.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data.replace({\"label\": {\"en\": 1, \"hi\": 0}}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data.replace({\"label\": {\"en\": 1, \"hi\": 0}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cricket</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raha</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yaha</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12744</th>\n",
       "      <td>challenge</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12745</th>\n",
       "      <td>winners</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12746</th>\n",
       "      <td>at</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12747</th>\n",
       "      <td>paradise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12748</th>\n",
       "      <td>photos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12749 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  label\n",
       "0        cricket      1\n",
       "1           chal      0\n",
       "2           raha      0\n",
       "3           hain      0\n",
       "4           yaha      0\n",
       "...          ...    ...\n",
       "12744  challenge      1\n",
       "12745    winners      1\n",
       "12746         at      1\n",
       "12747   paradise      1\n",
       "12748     photos      1\n",
       "\n",
       "[12749 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsplit_ratios = {\\n    \"80-20\": 0.2,\\n    \"99-1\": 0.01,\\n    \"75-25\": 0.25,\\n    \"60-40\": 0.4\\n    }\\nresults=[]\\nfor split_name, test_size in split_ratios.items():\\n    train_data, test_data = train_test_split(data, test_size=test_size, random_state=42)\\n    tokenizer = Tokenizer(num_words=10000)\\n    tokenizer.fit_on_texts(train_data[\"Word\"])\\n    X_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"Word\"]), maxlen=200)\\n    X_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"Word\"]), maxlen=200)\\n    Y_train = train_data[\"label\"].values\\n    Y_test = test_data[\"label\"].values    \\n    X_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"Word\"]), maxlen=200)\\n    X_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"Word\"]), maxlen=200)\\n    Y_train = train_data[\"label\"].values\\n    Y_test = test_data[\"label\"].values\\n    model = Sequential([\\n    Embedding(input_dim=10000, output_dim=128),\\n    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\\n    Dense(1, activation=\"sigmoid\")\\n    ])\\n    model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\\n    model.fit(X_train, Y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\\n    y_pred_prob = model.predict(X_test).flatten()\\n    y_pred_classes = (y_pred_prob > 0.5).astype(int)\\n    precision = precision_score(Y_test, y_pred_classes)\\n    recall = recall_score(Y_test, y_pred_classes)\\n    f1 = f1_score(Y_test, y_pred_classes)\\n    accuracy = accuracy_score(Y_test, y_pred_classes)\\n    results.append({\\n        \"Split\": split_name,\\n        \"Precision\": precision,\\n        \"Recall\": recall,\\n        \"F1 Score\": f1,\\n        \"Accuracy\": accuracy\\n    })\\n    if split_name == \"80-20\":\\n        # Confusion Matrix\\n        print(\"Confusion Matrix and ROC Curve for 80-20 Split:\")\\n        cm = confusion_matrix(Y_test, y_pred_classes)\\n        plt.figure(figsize=(8, 6))\\n        sns.heatmap(cm, annot=True, fmt=\\'d\\', cmap=\\'Blues\\', xticklabels=[\\'Negative\\', \\'Positive\\'], yticklabels=[\\'Negative\\', \\'Positive\\'])\\n        plt.xlabel(\\'Predicted\\')\\n        plt.ylabel(\\'Actual\\')\\n        plt.title(\\'Confusion Matrix (80-20 Split)\\')\\n        plt.show()\\n        fpr, tpr, _ = roc_curve(Y_test, y_pred_prob)\\n        roc_auc = auc(fpr, tpr)\\n        plt.figure(figsize=(8, 6))\\n        plt.plot(fpr, tpr, color=\\'blue\\', label=f\\'ROC Curve (AUC = {roc_auc:.2f})\\')\\n        plt.plot([0, 1], [0, 1], color=\\'gray\\', linestyle=\\'--\\')\\n        plt.xlabel(\\'False Positive Rate\\')\\n        plt.ylabel(\\'True Positive Rate\\')\\n        plt.title(\\'ROC Curve (80-20 Split)\\')\\n        plt.legend(loc=\"lower right\")\\n        plt.show()\\n    if split_name == \"99-1\":\\n        print(\"Confusion Matrix and ROC Curve for 99-1 Split:\")\\n        cm = confusion_matrix(Y_test, y_pred_classes)\\n        plt.figure(figsize=(8, 6))\\n        sns.heatmap(cm, annot=True, fmt=\\'d\\', cmap=\\'Blues\\', xticklabels=[\\'Negative\\', \\'Positive\\'], yticklabels=[\\'Negative\\', \\'Positive\\'])\\n        plt.xlabel(\\'Predicted\\')\\n        plt.ylabel(\\'Actual\\')\\n        plt.title(\\'Confusion Matrix (99-1 Split)\\')\\n        plt.show()\\n        fpr, tpr, _ = roc_curve(Y_test, y_pred_prob)\\n        roc_auc = auc(fpr, tpr)\\n        plt.figure(figsize=(8, 6))\\n        plt.plot(fpr, tpr, color=\\'blue\\', label=f\\'ROC Curve (AUC = {roc_auc:.2f})\\')\\n        plt.plot([0, 1], [0, 1], color=\\'gray\\', linestyle=\\'--\\')\\n        plt.xlabel(\\'False Positive Rate\\')\\n        plt.ylabel(\\'True Positive Rate\\')\\n        plt.title(\\'ROC Curve (99-1 Split)\\')\\n        plt.legend(loc=\"lower right\")\\n        plt.show()\\n    if split_name == \"75-25\":\\n        print(\"Confusion Matrix and ROC Curve for 75-25 Split:\")\\n        cm = confusion_matrix(Y_test, y_pred_classes)\\n        plt.figure(figsize=(8, 6))\\n        sns.heatmap(cm, annot=True, fmt=\\'d\\', cmap=\\'Blues\\', xticklabels=[\\'Negative\\', \\'Positive\\'], yticklabels=[\\'Negative\\', \\'Positive\\'])\\n        plt.xlabel(\\'Predicted\\')\\n        plt.ylabel(\\'Actual\\')\\n        plt.title(\\'Confusion Matrix (75-25 Split)\\')\\n        plt.show()\\n        fpr, tpr, _ = roc_curve(Y_test, y_pred_prob)\\n        roc_auc = auc(fpr, tpr)\\n        plt.figure(figsize=(8, 6))\\n        plt.plot(fpr, tpr, color=\\'blue\\', label=f\\'ROC Curve (AUC = {roc_auc:.2f})\\')\\n        plt.plot([0, 1], [0, 1], color=\\'gray\\', linestyle=\\'--\\')\\n        plt.xlabel(\\'False Positive Rate\\')\\n        plt.ylabel(\\'True Positive Rate\\')\\n        plt.title(\\'ROC Curve (75-25 Split)\\')\\n        plt.legend(loc=\"lower right\")\\n        plt.show()\\n    if split_name == \"60-40\":\\n        print(\"Confusion Matrix and ROC Curve for 60-40 Split:\")\\n        cm = confusion_matrix(Y_test, y_pred_classes)\\n        plt.figure(figsize=(8, 6))\\n        sns.heatmap(cm, annot=True, fmt=\\'d\\', cmap=\\'Blues\\', xticklabels=[\\'Negative\\', \\'Positive\\'], yticklabels=[\\'Negative\\', \\'Positive\\'])\\n        plt.xlabel(\\'Predicted\\')\\n        plt.ylabel(\\'Actual\\')\\n        plt.title(\\'Confusion Matrix (60-40 Split)\\')\\n        plt.show()\\n        fpr, tpr, _ = roc_curve(Y_test, y_pred_prob)\\n        roc_auc = auc(fpr, tpr)\\n        plt.figure(figsize=(8, 6))\\n        plt.plot(fpr, tpr, color=\\'blue\\', label=f\\'ROC Curve (AUC = {roc_auc:.2f})\\')\\n        plt.plot([0, 1], [0, 1], color=\\'gray\\', linestyle=\\'--\\')\\n        plt.xlabel(\\'False Positive Rate\\')\\n        plt.ylabel(\\'True Positive Rate\\')\\n        plt.title(\\'ROC Curve (60-40 Split)\\')\\n        plt.legend(loc=\"lower right\")\\n        plt.show()\\nresults_df = pd.DataFrame(results)\\nprint(\"Evaluation Metrics for Different Splits:\")\\nprint(results_df)\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "split_ratios = {\n",
    "    \"80-20\": 0.2,\n",
    "    \"99-1\": 0.01,\n",
    "    \"75-25\": 0.25,\n",
    "    \"60-40\": 0.4\n",
    "    }\n",
    "results=[]\n",
    "for split_name, test_size in split_ratios.items():\n",
    "    train_data, test_data = train_test_split(data, test_size=test_size, random_state=42)\n",
    "    tokenizer = Tokenizer(num_words=10000)\n",
    "    tokenizer.fit_on_texts(train_data[\"Word\"])\n",
    "    X_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"Word\"]), maxlen=200)\n",
    "    X_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"Word\"]), maxlen=200)\n",
    "    Y_train = train_data[\"label\"].values\n",
    "    Y_test = test_data[\"label\"].values    \n",
    "    X_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"Word\"]), maxlen=200)\n",
    "    X_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"Word\"]), maxlen=200)\n",
    "    Y_train = train_data[\"label\"].values\n",
    "    Y_test = test_data[\"label\"].values\n",
    "    model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, Y_train, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n",
    "    y_pred_prob = model.predict(X_test).flatten()\n",
    "    y_pred_classes = (y_pred_prob > 0.5).astype(int)\n",
    "    precision = precision_score(Y_test, y_pred_classes)\n",
    "    recall = recall_score(Y_test, y_pred_classes)\n",
    "    f1 = f1_score(Y_test, y_pred_classes)\n",
    "    accuracy = accuracy_score(Y_test, y_pred_classes)\n",
    "    results.append({\n",
    "        \"Split\": split_name,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Accuracy\": accuracy\n",
    "    })\n",
    "    if split_name == \"80-20\":\n",
    "        # Confusion Matrix\n",
    "        print(\"Confusion Matrix and ROC Curve for 80-20 Split:\")\n",
    "        cm = confusion_matrix(Y_test, y_pred_classes)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix (80-20 Split)')\n",
    "        plt.show()\n",
    "        fpr, tpr, _ = roc_curve(Y_test, y_pred_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve (80-20 Split)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    if split_name == \"99-1\":\n",
    "        print(\"Confusion Matrix and ROC Curve for 99-1 Split:\")\n",
    "        cm = confusion_matrix(Y_test, y_pred_classes)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix (99-1 Split)')\n",
    "        plt.show()\n",
    "        fpr, tpr, _ = roc_curve(Y_test, y_pred_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve (99-1 Split)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    if split_name == \"75-25\":\n",
    "        print(\"Confusion Matrix and ROC Curve for 75-25 Split:\")\n",
    "        cm = confusion_matrix(Y_test, y_pred_classes)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix (75-25 Split)')\n",
    "        plt.show()\n",
    "        fpr, tpr, _ = roc_curve(Y_test, y_pred_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve (75-25 Split)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    if split_name == \"60-40\":\n",
    "        print(\"Confusion Matrix and ROC Curve for 60-40 Split:\")\n",
    "        cm = confusion_matrix(Y_test, y_pred_classes)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix (60-40 Split)')\n",
    "        plt.show()\n",
    "        fpr, tpr, _ = roc_curve(Y_test, y_pred_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve (60-40 Split)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Evaluation Metrics for Different Splits:\")\n",
    "print(results_df)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#75-25 gives the bestt result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cricket</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>raha</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yaha</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12744</th>\n",
       "      <td>challenge</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12745</th>\n",
       "      <td>winners</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12746</th>\n",
       "      <td>at</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12747</th>\n",
       "      <td>paradise</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12748</th>\n",
       "      <td>photos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12749 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  label\n",
       "0        cricket      1\n",
       "1           chal      0\n",
       "2           raha      0\n",
       "3           hain      0\n",
       "4           yaha      0\n",
       "...          ...    ...\n",
       "12744  challenge      1\n",
       "12745    winners      1\n",
       "12746         at      1\n",
       "12747   paradise      1\n",
       "12748     photos      1\n",
       "\n",
       "[12749 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 158ms/step - accuracy: 0.5686 - loss: 0.6640 - val_accuracy: 0.8045 - val_loss: 0.4159\n",
      "Epoch 2/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 152ms/step - accuracy: 0.9369 - loss: 0.2681 - val_accuracy: 0.8045 - val_loss: 0.3483\n",
      "Epoch 3/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 155ms/step - accuracy: 0.9700 - loss: 0.0920 - val_accuracy: 0.7996 - val_loss: 0.3590\n",
      "Epoch 4/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 150ms/step - accuracy: 0.9732 - loss: 0.0714 - val_accuracy: 0.8006 - val_loss: 0.3522\n",
      "Epoch 5/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 147ms/step - accuracy: 0.9725 - loss: 0.0591 - val_accuracy: 0.8020 - val_loss: 0.3543\n",
      "Epoch 6/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 156ms/step - accuracy: 0.9746 - loss: 0.0540 - val_accuracy: 0.8045 - val_loss: 0.3484\n",
      "Epoch 7/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 179ms/step - accuracy: 0.9744 - loss: 0.0558 - val_accuracy: 0.7933 - val_loss: 0.3518\n",
      "Epoch 8/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 172ms/step - accuracy: 0.9780 - loss: 0.0512 - val_accuracy: 0.7957 - val_loss: 0.3507\n",
      "Epoch 9/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 158ms/step - accuracy: 0.9749 - loss: 0.0560 - val_accuracy: 0.8090 - val_loss: 0.3431\n",
      "Epoch 10/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 154ms/step - accuracy: 0.9737 - loss: 0.0569 - val_accuracy: 0.7853 - val_loss: 0.3723\n",
      "Epoch 11/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 156ms/step - accuracy: 0.9708 - loss: 0.0609 - val_accuracy: 0.8107 - val_loss: 0.3498\n",
      "Epoch 12/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 174ms/step - accuracy: 0.9735 - loss: 0.0525 - val_accuracy: 0.7947 - val_loss: 0.3593\n",
      "Epoch 13/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 184ms/step - accuracy: 0.9719 - loss: 0.0538 - val_accuracy: 0.8156 - val_loss: 0.3621\n",
      "Epoch 14/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 182ms/step - accuracy: 0.9730 - loss: 0.0561 - val_accuracy: 0.7954 - val_loss: 0.3582\n",
      "Epoch 15/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 189ms/step - accuracy: 0.9745 - loss: 0.0572 - val_accuracy: 0.8041 - val_loss: 0.3500\n",
      "Epoch 16/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 212ms/step - accuracy: 0.9760 - loss: 0.0516 - val_accuracy: 0.8072 - val_loss: 0.3434\n",
      "Epoch 17/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 215ms/step - accuracy: 0.9740 - loss: 0.0556 - val_accuracy: 0.8055 - val_loss: 0.3476\n",
      "Epoch 18/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 213ms/step - accuracy: 0.9724 - loss: 0.0537 - val_accuracy: 0.8114 - val_loss: 0.3471\n",
      "Epoch 19/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 192ms/step - accuracy: 0.9711 - loss: 0.0537 - val_accuracy: 0.8024 - val_loss: 0.3522\n",
      "Epoch 20/20\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 191ms/step - accuracy: 0.9769 - loss: 0.0488 - val_accuracy: 0.8017 - val_loss: 0.3535\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_2=[]\n",
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_data[\"Word\"])\n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"Word\"]), maxlen=200)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"Word\"]), maxlen=200)\n",
    "Y_train = train_data[\"label\"].values\n",
    "Y_test = test_data[\"label\"].values    \n",
    "X_train = pad_sequences(tokenizer.texts_to_sequences(train_data[\"Word\"]), maxlen=200)\n",
    "X_test = pad_sequences(tokenizer.texts_to_sequences(test_data[\"Word\"]), maxlen=200)\n",
    "Y_train = train_data[\"label\"].values\n",
    "Y_test = test_data[\"label\"].values\n",
    "model = Sequential([\n",
    "Embedding(input_dim=10000, output_dim=128),\n",
    "LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=64, validation_split=0.3, verbose=1)\n",
    "y_pred_prob = model.predict(X_test).flatten()\n",
    "y_pred_classes = (y_pred_prob > 0.5).astype(int)\n",
    "precision = precision_score(Y_test, y_pred_classes)\n",
    "recall = recall_score(Y_test, y_pred_classes)\n",
    "f1 = f1_score(Y_test, y_pred_classes)\n",
    "accuracy = accuracy_score(Y_test, y_pred_classes)\n",
    "results_2.append({\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1 Score\": f1,\n",
    "    \"Accuracy\": accuracy\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Precision': 0.7634973721930244, 'Recall': 0.9506246281975015, 'F1 Score': 0.8468468468468469, 'Accuracy': 0.8186951066499373}]\n"
     ]
    }
   ],
   "source": [
    "print(results_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_label(review):\n",
    "    sequence = tokenizer.texts_to_sequences([review])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=200)\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    sentiment = \"en\" if prediction[0][0] > 0.5 else \"hi\"\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "review=\"bhai\"\n",
    "print(predict_label(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'C:\\Users\\sujay\\Desktop\\Chatbot\\models\\tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(r'C:\\Users\\sujay\\Desktop\\Chatbot\\models\\Hinglish_Classification_LSTM_Model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
