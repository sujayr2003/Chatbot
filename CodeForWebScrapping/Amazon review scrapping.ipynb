{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:57<00:00,  5.85s/it]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.amazon.in/s?k=mobiles&crid=3GGHIO8WGFWGJ&sprefix=%2Caps%2C230&ref=nb_sb_ss_recent_1_0_recent\")\n",
    "html_data_1=BeautifulSoup(driver.page_source,'html.parser')\n",
    "No_of_pages = html_data_1.find('span',{'class':'s-pagination-item s-pagination-disabled'}).text\n",
    "titles=[]\n",
    "images=[]\n",
    "ratings=[]\n",
    "prices=[]\n",
    "product_urls=[]\n",
    "for i in tqdm(range(int(No_of_pages))):\n",
    "   url = 'https://www.amazon.in/s?k=mobiles&crid=2944PM084A0K4&sprefix=mobiles%2Caps%2C271&ref=nb_sb_noss_1&page='+str(i+1)\n",
    "   driver.get(url)\n",
    "   time.sleep(3)\n",
    "   html_data_2=BeautifulSoup(driver.page_source,'html.parser')\n",
    "   products=html_data_2.find_all('div',{'data-component-type':'s-search-result'})\n",
    "   for product in products:\n",
    "      title=product.find('h2',{'class':'a-size-mini a-spacing-none a-color-base s-line-clamp-2'}).text\n",
    "      titles.append(title)\n",
    "      img = product.find('img')['src']\n",
    "      images.append(img)\n",
    "      rating=product.find('span',{'class':'a-icon-alt'})\n",
    "      if rating == None:\n",
    "         rating='No Rating'\n",
    "      else:\n",
    "         rating=product.find('span',{'class':'a-icon-alt'}).text\n",
    "      ratings.append(rating)\n",
    "      price = product.find('span',{'class':'a-price-whole'})\n",
    "      if price==None or product.find('span',{'aria-label':'Currently unavailable.'}) or product.find('span',{'class':'a-size-base a-color-secondary'}):\n",
    "         price='No Price'\n",
    "      else:\n",
    "         price = '₹'+product.find('span',{'class':'a-price-whole'}).text\n",
    "      prices.append(price)\n",
    "      product_url=product.find('a')\n",
    "      product_fullurl=\"https://amazon.in/\"+product_url['href']\n",
    "      product_urls.append(product_fullurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"titles\":titles,\"images\":images,\"ratings\":ratings,\"prices\":prices,\"product_urls\":product_urls})\n",
    "data.to_csv(r\"C:\\Users\\sujay\\Desktop\\Chatbot\\CSVFilesObtainedAfterWebscrapping\\Amazon\\amazon_reviews_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "driver=webdriver.Chrome()\n",
    "review_links=[]\n",
    "for i in range(len(product_urls)):\n",
    "    driver.get(product_urls[i])\n",
    "    review_data = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    reviewlink = review_data.find('a', {'data-hook': 'see-all-reviews-link-foot'})\n",
    "    if reviewlink is None:\n",
    "        link = 'No Link'\n",
    "    else:\n",
    "        link = \"https://www.amazon.in\" + reviewlink['href']\n",
    "    review_links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.DataFrame({'review':review_links})\n",
    "data1.to_csv(r'C:\\Users\\sujay\\Desktop\\Chatbot\\CSVFilesObtainedAfterWebscrapping\\Amazon\\reviewlinks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('reviewlinks.csv')\n",
    "df=df[df.review!='No Link']\n",
    "df.to_csv(r\"C:\\Users\\sujay\\Desktop\\Chatbot\\CSVFilesObtainedAfterWebscrapping\\Amazon\\NewreviewLinks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.read_csv(r\"C:\\Users\\sujay\\Desktop\\Chatbot\\CSVFilesObtainedAfterWebscrapping\\Amazon\\NewreviewLinks.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "# Path to your existing browser profile\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"user-data-dir=/path/to/your/profile\")\n",
    "\n",
    "# Set up the Chrome WebDriver with the profile\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "def scrape_amazon_reviews(product_url):\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    driver.get(product_url)\n",
    "    \n",
    "    reviews_text = []\n",
    "    names = []\n",
    "    rating_dates = []\n",
    "    titles = []\n",
    "    ratingsss=[]\n",
    "    reviewproducttitles=[]\n",
    "    while product_url is not None:\n",
    "        time.sleep(5)  \n",
    "        html_data = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        reviews = html_data\n",
    "        \n",
    "        for review in reviews:\n",
    "            all_reviews=review.find_all('div',{'data-hook':'review','class':'a-section review aok-relative'})\n",
    "\n",
    "            for r in all_reviews:\n",
    "                review_text = r.find('span', {'data-hook': 'review-body','class':'a-size-base review-text review-text-content'}).text.strip()\n",
    "                reviews_text.append(review_text)\n",
    "                name = r.find('span', {'class': 'a-profile-name'}).text.strip()\n",
    "                names.append(name)\n",
    "                ratingss = r.find('span', {'class': 'a-icon-alt'}).text\n",
    "                ratingsss.append(ratingss)\n",
    "                rating_date = r.find('span', {'data-hook': 'review-date'}).text\n",
    "                rating_dates.append(rating_date)\n",
    "                title = review.find('a', {'data-hook': 'review-title'})\n",
    "                if title==None:\n",
    "                   title='No Title'\n",
    "                else:\n",
    "                    title = review.find('a', {'data-hook': 'review-title'}).text.strip()\n",
    "                titles.append(title[19:])\n",
    "\n",
    "            reviewproducttitle = review.find('a', {'data-hook': 'product-link'})\n",
    "            if reviewproducttitle==None:\n",
    "                reviewproducttitle='No Product Title'\n",
    "            else:\n",
    "                reviewproducttitle = review.find('a', {'data-hook': 'product-link'})\n",
    "            for _ in range(len(all_reviews)):\n",
    "                reviewproducttitles.append(reviewproducttitle.text)\n",
    "        url_check = html_data.find('li', {'class': 'a-last'})\n",
    "        if url_check is None or url_check.a is None:\n",
    "            product_url = None  # No more pages to navigate\n",
    "        else:\n",
    "            product_url = url_check.a['href']\n",
    "            driver.find_element(By.LINK_TEXT,\"Next page\").click()\n",
    "    \n",
    "    driver.quit()\n",
    "    return reviews_text, names, ratingsss, rating_dates, titles,reviewproducttitles\n",
    "\n",
    "\n",
    "all_reviews_text_0 = []\n",
    "all_names_0 = []\n",
    "all_ratings_0 = []\n",
    "all_rating_dates_0 = []\n",
    "all_titles_0 = []\n",
    "all_review_product_titles=[]\n",
    "for url in new_df.review[0:101]:\n",
    "    reviews_text, names, ratingsss, rating_dates, titles,reviewproducttitles = scrape_amazon_reviews(url)\n",
    "    all_reviews_text_0.extend(reviews_text)\n",
    "    all_names_0.extend(names)\n",
    "    all_ratings_0.extend(ratingsss)\n",
    "    all_rating_dates_0.extend(rating_dates)\n",
    "    all_titles_0.extend(titles)\n",
    "    all_review_product_titles.extend(reviewproducttitles)\n",
    "    #Add a separator for each product\n",
    "    all_reviews_text_0.append('-------')\n",
    "    all_names_0.append('-------')\n",
    "    all_ratings_0.append('-------')\n",
    "    all_rating_dates_0.append('-------')\n",
    "    all_titles_0.append('-------')\n",
    "    all_review_product_titles.append('-------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Product Title':all_review_product_titles,\n",
    "    'Title': all_titles_0,\n",
    "    'Name': all_names_0,\n",
    "    'Ratings':all_ratings_0,\n",
    "    'Rating Date': all_rating_dates_0,\n",
    "    'Review Text': all_reviews_text_0\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "# Path to your existing browser profile\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"user-data-dir=/path/to/your/profile\")\n",
    "\n",
    "# Set up the Chrome WebDriver with the profile\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "def scrape_amazon_reviews(product_url):\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    driver.get(product_url)\n",
    "    \n",
    "    reviews_text = []\n",
    "    names = []\n",
    "    rating_dates = []\n",
    "    titles = []\n",
    "    ratingsss=[]\n",
    "    reviewproducttitles=[]\n",
    "    while product_url is not None:\n",
    "        time.sleep(5)  \n",
    "        html_data = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        reviews = html_data\n",
    "        \n",
    "        for review in reviews:\n",
    "            all_reviews=review.find_all('div',{'data-hook':'review','class':'a-section review aok-relative'})\n",
    "\n",
    "            for r in all_reviews:\n",
    "                review_text = r.find('span', {'data-hook': 'review-body','class':'a-size-base review-text review-text-content'}).text.strip()\n",
    "                reviews_text.append(review_text)\n",
    "                name = r.find('span', {'class': 'a-profile-name'}).text.strip()\n",
    "                names.append(name)\n",
    "                ratingss = r.find('span', {'class': 'a-icon-alt'}).text\n",
    "                ratingsss.append(ratingss)\n",
    "                rating_date = r.find('span', {'data-hook': 'review-date'}).text\n",
    "                rating_dates.append(rating_date)\n",
    "                title = review.find('a', {'data-hook': 'review-title'})\n",
    "                if title==None:\n",
    "                   title='No Title'\n",
    "                else:\n",
    "                    title = review.find('a', {'data-hook': 'review-title'}).text.strip()\n",
    "                titles.append(title[19:])\n",
    "\n",
    "            reviewproducttitle = review.find('a', {'data-hook': 'product-link'})\n",
    "            if reviewproducttitle==None:\n",
    "                reviewproducttitle='No Product Title'\n",
    "            else:\n",
    "                reviewproducttitle = review.find('a', {'data-hook': 'product-link'})\n",
    "            for _ in range(len(all_reviews)):\n",
    "                reviewproducttitles.append(reviewproducttitle.text)\n",
    "        url_check = html_data.find('li', {'class': 'a-last'})\n",
    "        if url_check is None or url_check.a is None:\n",
    "            product_url = None  # No more pages to navigate\n",
    "        else:\n",
    "            product_url = url_check.a['href']\n",
    "            driver.find_element(By.LINK_TEXT,\"Next page\").click()\n",
    "    \n",
    "    driver.quit()\n",
    "    return reviews_text, names, ratingsss, rating_dates, titles,reviewproducttitles\n",
    "\n",
    "\n",
    "all_reviews_text_1 = []\n",
    "all_names_1 = []\n",
    "all_ratings_1 = []\n",
    "all_rating_dates_1 = []\n",
    "all_titles_1 = []\n",
    "all_review_product_titles=[]\n",
    "for url in new_df.review[101:201]:\n",
    "    reviews_text, names, ratingsss, rating_dates, titles,reviewproducttitles = scrape_amazon_reviews(url)\n",
    "    all_reviews_text_1.extend(reviews_text)\n",
    "    all_names_1.extend(names)\n",
    "    all_ratings_1.extend(ratingsss)\n",
    "    all_rating_dates_1.extend(rating_dates)\n",
    "    all_titles_1.extend(titles)\n",
    "    all_review_product_titles.extend(reviewproducttitles)\n",
    "    #Add a separator for each product\n",
    "    all_reviews_text_1.append('-------')\n",
    "    all_names_1.append('-------')\n",
    "    all_ratings_1.append('-------')\n",
    "    all_rating_dates_1.append('-------')\n",
    "    all_titles_1.append('-------')\n",
    "    all_review_product_titles.append('-------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({\n",
    "    'Product Title':all_review_product_titles,\n",
    "    'Title': all_titles_1,\n",
    "    'Name': all_names_1,\n",
    "    'Ratings':all_ratings_1,\n",
    "    'Rating Date': all_rating_dates_1,\n",
    "    'Review Text': all_reviews_text_1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "# Path to your existing browser profile\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"user-data-dir=/path/to/your/profile\")\n",
    "\n",
    "# Set up the Chrome WebDriver with the profile\n",
    "service = Service(ChromeDriverManager().install())\n",
    "\n",
    "def scrape_amazon_reviews(product_url):\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    driver.get(product_url)\n",
    "    \n",
    "    reviews_text = []\n",
    "    names = []\n",
    "    rating_dates = []\n",
    "    titles = []\n",
    "    ratingsss=[]\n",
    "    reviewproducttitles=[]\n",
    "    while product_url is not None:\n",
    "        time.sleep(5)  \n",
    "        html_data = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        reviews = html_data\n",
    "        \n",
    "        for review in reviews:\n",
    "            all_reviews=review.find_all('div',{'data-hook':'review','class':'a-section review aok-relative'})\n",
    "\n",
    "            for r in all_reviews:\n",
    "                review_text = r.find('span', {'data-hook': 'review-body','class':'a-size-base review-text review-text-content'}).text.strip()\n",
    "                reviews_text.append(review_text)\n",
    "                name = r.find('span', {'class': 'a-profile-name'}).text.strip()\n",
    "                names.append(name)\n",
    "                ratingss = r.find('span', {'class': 'a-icon-alt'}).text\n",
    "                ratingsss.append(ratingss)\n",
    "                rating_date = r.find('span', {'data-hook': 'review-date'}).text\n",
    "                rating_dates.append(rating_date)\n",
    "                title = review.find('a', {'data-hook': 'review-title'})\n",
    "                if title==None:\n",
    "                   title='No Title'\n",
    "                else:\n",
    "                    title = review.find('a', {'data-hook': 'review-title'}).text.strip()\n",
    "                titles.append(title[19:])\n",
    "\n",
    "            reviewproducttitle = review.find('a', {'data-hook': 'product-link'})\n",
    "            if reviewproducttitle==None:\n",
    "                reviewproducttitle='No Product Title'\n",
    "            else:\n",
    "                reviewproducttitle = review.find('a', {'data-hook': 'product-link'})\n",
    "            for _ in range(len(all_reviews)):\n",
    "                reviewproducttitles.append(reviewproducttitle.text)\n",
    "        url_check = html_data.find('li', {'class': 'a-last'})\n",
    "        if url_check is None or url_check.a is None:\n",
    "            product_url = None  # No more pages to navigate\n",
    "        else:\n",
    "            product_url = url_check.a['href']\n",
    "            driver.find_element(By.LINK_TEXT,\"Next page\").click()\n",
    "    \n",
    "    driver.quit()\n",
    "    return reviews_text, names, ratingsss, rating_dates, titles,reviewproducttitles\n",
    "\n",
    "\n",
    "all_reviews_text_2 = []\n",
    "all_names_2 = []\n",
    "all_ratings_2 = []\n",
    "all_rating_dates_2 = []\n",
    "all_titles_2 = []\n",
    "all_review_product_titles=[]\n",
    "for url in new_df.review[201:]:\n",
    "    reviews_text, names, ratingsss, rating_dates, titles ,reviewproducttitles= scrape_amazon_reviews(url)\n",
    "    all_reviews_text_2.extend(reviews_text)\n",
    "    all_names_2.extend(names)\n",
    "    all_ratings_2.extend(ratingsss)\n",
    "    all_rating_dates_2.extend(rating_dates)\n",
    "    all_titles_2.extend(titles)\n",
    "    all_review_product_titles.extend(reviewproducttitles)\n",
    "    #Add a separator for each product\n",
    "    all_reviews_text_2.append('-------')\n",
    "    all_names_2.append('-------')\n",
    "    all_ratings_2.append('-------')\n",
    "    all_rating_dates_2.append('-------')\n",
    "    all_titles_2.append('-------')\n",
    "    all_review_product_titles.append('-------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame\n",
    "df3 = pd.DataFrame({\n",
    "    'Product Title':all_review_product_titles,\n",
    "    'Title': all_titles_2,\n",
    "    'Name': all_names_2,\n",
    "    'Ratings':all_ratings_2,\n",
    "    'Rating Date': all_rating_dates_2,\n",
    "    'Review Text': all_reviews_text_2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Product Title</th>\n",
       "      <th>Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Rating Date</th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Redmi 13 5g Black Diamond 6GB 128GB</td>\n",
       "      <td>Great phone great specs</td>\n",
       "      <td>AD Pal</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Reviewed in India on 29 July 2024</td>\n",
       "      <td>The Worth it phone, I've tried many other bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Redmi 13 5g Black Diamond 6GB 128GB</td>\n",
       "      <td>Great phone great specs</td>\n",
       "      <td>Raja</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>Reviewed in India on 17 August 2024</td>\n",
       "      <td>I used this mobile, past 30 days. It worth for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Redmi 13 5g Black Diamond 6GB 128GB</td>\n",
       "      <td>Great phone great specs</td>\n",
       "      <td>Bablu Kumar Mandal</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>Reviewed in India on 8 August 2024</td>\n",
       "      <td>This is really a good 5G phone in this budget ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Redmi 13 5g Black Diamond 6GB 128GB</td>\n",
       "      <td>Great phone great specs</td>\n",
       "      <td>Rahul Kumar Sharma</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Reviewed in India on 10 August 2024</td>\n",
       "      <td>The phone has an eye-catching, contemporary de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Redmi 13 5g Black Diamond 6GB 128GB</td>\n",
       "      <td>Great phone great specs</td>\n",
       "      <td>Dinesh Bhika Bhadane</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>Reviewed in India on 15 August 2024</td>\n",
       "      <td>Thanks Amazon for the right products with good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28170</th>\n",
       "      <td>12126</td>\n",
       "      <td>Spigen Ultra Hybrid Back Cover Case for iPhone...</td>\n",
       "      <td>Durable cover</td>\n",
       "      <td>Sada</td>\n",
       "      <td>3.0 out of 5 stars</td>\n",
       "      <td>Reviewed in India on 19 October 2021</td>\n",
       "      <td>The item is good for about 6 months, the slowl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28171</th>\n",
       "      <td>12127</td>\n",
       "      <td>Spigen Ultra Hybrid Back Cover Case for iPhone...</td>\n",
       "      <td>Durable cover</td>\n",
       "      <td>Pratik Pandey</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>Reviewed in India on 12 July 2021</td>\n",
       "      <td>Very Nice product. Perfectly fir to iphone Xs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28172</th>\n",
       "      <td>12128</td>\n",
       "      <td>Spigen Ultra Hybrid Back Cover Case for iPhone...</td>\n",
       "      <td>Durable cover</td>\n",
       "      <td>Srikanth</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>Reviewed in India on 17 September 2020</td>\n",
       "      <td>Quality good but within a week sides turned in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28173</th>\n",
       "      <td>12129</td>\n",
       "      <td>Spigen Ultra Hybrid Back Cover Case for iPhone...</td>\n",
       "      <td>Durable cover</td>\n",
       "      <td>Keshav sharma</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>Reviewed in India on 18 June 2021</td>\n",
       "      <td>Turns yellow after 6 months of use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28174</th>\n",
       "      <td>12130</td>\n",
       "      <td>-------</td>\n",
       "      <td>-------</td>\n",
       "      <td>-------</td>\n",
       "      <td>-------</td>\n",
       "      <td>-------</td>\n",
       "      <td>-------</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28175 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                      Product Title  \\\n",
       "0               0                Redmi 13 5g Black Diamond 6GB 128GB   \n",
       "1               1                Redmi 13 5g Black Diamond 6GB 128GB   \n",
       "2               2                Redmi 13 5g Black Diamond 6GB 128GB   \n",
       "3               3                Redmi 13 5g Black Diamond 6GB 128GB   \n",
       "4               4                Redmi 13 5g Black Diamond 6GB 128GB   \n",
       "...           ...                                                ...   \n",
       "28170       12126  Spigen Ultra Hybrid Back Cover Case for iPhone...   \n",
       "28171       12127  Spigen Ultra Hybrid Back Cover Case for iPhone...   \n",
       "28172       12128  Spigen Ultra Hybrid Back Cover Case for iPhone...   \n",
       "28173       12129  Spigen Ultra Hybrid Back Cover Case for iPhone...   \n",
       "28174       12130                                            -------   \n",
       "\n",
       "                         Title                  Name             Ratings  \\\n",
       "0      Great phone great specs                AD Pal  5.0 out of 5 stars   \n",
       "1      Great phone great specs                  Raja  4.0 out of 5 stars   \n",
       "2      Great phone great specs    Bablu Kumar Mandal  4.0 out of 5 stars   \n",
       "3      Great phone great specs    Rahul Kumar Sharma  5.0 out of 5 stars   \n",
       "4      Great phone great specs  Dinesh Bhika Bhadane  5.0 out of 5 stars   \n",
       "...                        ...                   ...                 ...   \n",
       "28170            Durable cover                  Sada  3.0 out of 5 stars   \n",
       "28171            Durable cover         Pratik Pandey  4.0 out of 5 stars   \n",
       "28172            Durable cover              Srikanth  4.0 out of 5 stars   \n",
       "28173            Durable cover         Keshav sharma  4.0 out of 5 stars   \n",
       "28174                  -------               -------             -------   \n",
       "\n",
       "                                  Rating Date  \\\n",
       "0           Reviewed in India on 29 July 2024   \n",
       "1         Reviewed in India on 17 August 2024   \n",
       "2          Reviewed in India on 8 August 2024   \n",
       "3         Reviewed in India on 10 August 2024   \n",
       "4         Reviewed in India on 15 August 2024   \n",
       "...                                       ...   \n",
       "28170    Reviewed in India on 19 October 2021   \n",
       "28171       Reviewed in India on 12 July 2021   \n",
       "28172  Reviewed in India on 17 September 2020   \n",
       "28173       Reviewed in India on 18 June 2021   \n",
       "28174                                 -------   \n",
       "\n",
       "                                             Review Text  \n",
       "0      The Worth it phone, I've tried many other bran...  \n",
       "1      I used this mobile, past 30 days. It worth for...  \n",
       "2      This is really a good 5G phone in this budget ...  \n",
       "3      The phone has an eye-catching, contemporary de...  \n",
       "4      Thanks Amazon for the right products with good...  \n",
       "...                                                  ...  \n",
       "28170  The item is good for about 6 months, the slowl...  \n",
       "28171     Very Nice product. Perfectly fir to iphone Xs.  \n",
       "28172  Quality good but within a week sides turned in...  \n",
       "28173                 Turns yellow after 6 months of use  \n",
       "28174                                            -------  \n",
       "\n",
       "[28175 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.concat([df, df2, df3], ignore_index=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.to_csv(r\"C:\\Users\\sujay\\Desktop\\Chatbot\\CSVFilesObtainedAfterWebscrapping\\Amazon\\amazon_reviews_final.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
